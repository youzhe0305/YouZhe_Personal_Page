<!DOCTYPE html>
<html>
<head>

	<title>You-Zhe Xie</title>
	<link href="css/bootstrap.css" rel="stylesheet">
	<link rel="stylesheet" type="text/css" href="css/styles.css">
	<link rel="stylesheet" href="./assets/css/fontawesome.all.min.css">
	<!-- <link href="css/fontawesome-all.css" rel="stylesheet"> -->
	<script defer src="./js/fontawesome.all.min.js"></script>
	<link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="icon" href="images/cube-solid.svg">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

	
</head>
<body data-spy="scroll" data-target=".fixed-top" class='has-animations'>

	<!-- Navbar -->
	<nav class="navbar navbar-expand-lg navbar-light bg-light fixed-top" style="height: 80px;">
	<div class="container" style="height: 10px;">
		<a class="navbar-brand" href="#">You-Zhe Xie</a>
		<!-- <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
		aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
		<span class="navbar-toggler-icon"></span> -->
		</button>
		<div class="collapse navbar-collapse" id="navbarNav">
		<ul class="navbar-nav  w-100">
			<li class="nav-item">
			<a class="nav-link" href="#Experience">Experience</a>
			</li>
			<li class="nav-item">
			<a class="nav-link" href="#News">News</a>
			</li>
			<li class="nav-item">
			<a class="nav-link" href="#Publications">Publications</a>
			</li>
			<li class="nav-item">
			<a class="nav-link" href="#Projects">Projects</a>
			</li>
		</ul>
		</div>
	</div>
	</nav>

	<div class="container section-offset">
		<div class="intro">
			<div class="row">
				<div class="col-lg-8 is-revealing is-header">
					<h1 class="name"><strong>ğŸ’« You-Zhe</strong> Xie</h1>
					<!--<span class="job-title">Ph.D. Student</span>-->
					<!--<span class="email">yclee@umd.edu</span>-->
					<h2 class="lead">Computer Science Bachelorâ€™s Student
					<br/>National Yang Ming Chiao Tung University</h2>
				</div>
				<div class="col-lg-4">
					<img class="img-fluid" src="images/profile.png" alt="alternative" style="max-width: 80%; margin-left: 20%; margin-right: 20%;">
				</div>
			</div>
			<div class="is-revealing is-header">
				<p>
					I am currently a  3rd-year Bachelorâ€™s student in Institute of Computer Science at National Yang Ming Chiao Tung
					University, advised by Prof. <a href="https://yulunalexliu.github.io/" target="_blank">Yu-Lun Liu</a>.
					My research interest focuses on 3D Computer Vision.
				  </p>
			</div>
			<a class="btn is-revealing is-header" href="files/You_Zhe_Xie_Resume.pdf"><i class="fab fas fa-file-alt"></i>&nbsp CV</a>
			<a class="btn is-revealing is-header" href="youzhe0305.cs12@nycu.edu.tw"><i class="fab fas fa-envelope"></i>&nbsp Email</a>
			<a class="btn is-revealing is-header" href="https://youzhe0305.github.io/"><i class="fa fa-folder-open"></i>&nbsp Projects Page</a>
			<a class="btn is-revealing is-header" href="https://scholar.google.com/citations?user=DHDR6DAAAAAJ"><i class="fab fa-google"></i>&nbsp Google Scholar</a>
			<a class="btn is-revealing is-header" href="https://github.com/youzhe0305"><i class="fab fa-github"></i>&nbsp Github</a>
			<a class="btn is-revealing is-header" href="https://www.linkedin.com/in/you-zhe-xie-6464682b3/"><i class="fab fa-linkedin-in"></i>&nbsp LinkedIn</a>

		</div>
		
	</div>

	<!-- Timeeline -->

	<div class="container section-offset" id="Experience">
		<!-- <h2 class="section-title timeline">Experience</h2> -->
		<ol class="timeline">
			<li class="is-revealing is-header">
				<!-- <span class="point"></span> -->
				<img src="images/Academia_Sinica_Emblem.png" class="logo" style="transform: scale(0.75);"/>
				<p class="description">
					â–¶ï¸ Academia Sinica<br>
					ğŸ’¼ Research intern under Dr. <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html" target="_blank">Jun-Cheng Chen</a><br>
					ğŸ•— 07/2025 - 08/2025
				</p>
				<p class="date"></p>
			</li>
			<li class="is-revealing is-header">
				<!-- <span class="point"></span> -->
				<img src="images/WorldQuant.png" class="logo" style="transform: scale(0.75); "/>
				<p class="description">
					â–¶ï¸ WorldQuant<br>
					ğŸ’¼ Brain Consultant<br>
					ğŸ•— 02/2025 - Present
				</p>
				<p class="date"></p>
			</li>
			<li class="is-revealing is-header">
				<!-- <span class="point"></span> -->
				<img src="images/GDSC.jpg" class="logo" style="transform: scale(0.75); "/>
				<p class="description">
					â–¶ï¸ Google Developer Student Club<br>
					ğŸ’¼ Mentor of Gen CV<br>
					ğŸ•— 09/2024 - 06/2025
				</p>
				<p class="date"></p>
			</li>
			<li class="is-revealing is-header">
				<!-- <span class="point"></span> -->
				<img src="images/nycu.png" class="logo" style="transform: scale(0.75);"/>
				<p class="description">
					â–¶ï¸ National Yang Ming Chiao Tung University<br>
					ğŸ’¼ B.S. of Computer Science<br>
					ğŸ•— 09/2023 - present
				</p>
			</li>
		</ol>
	</div>


	<div class="container section-offset" id="News">
		<h2 class="section-title" >News</h2>
    
		<div style="border: 1px solid #dddddd; padding: 20px;">
			<p><strong>ğŸ‰ 09/2025: </strong>"Every Camera Effect, Every Time, All at Once: 4D Gaussian Ray Tracing for Physics-based Camera Effect Data Generation" accepted by <strong><u>NeurIPS 2025 SpaVLE workshop</u></strong>!!!</p>
			<p><strong>ğŸ… 09/2025: </strong>Awarded with <strong>Core Fundamental Course Award (æ ¸å¿ƒåŸºç¤èª²ç¨‹ç)</strong> of Computer Organization !!!</p>
			<p><strong>ğŸ‰ 06/2025: </strong>"StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions" accepted by <strong><u>ICCV 2025</u></strong>!!!</p>
			<p><strong>ğŸ‰ 06/2025: </strong>Completed <strong><u>GDSC Global Program</u></strong> in NYCU as core member!!!</p>
			<p><strong>ğŸ’¼ 04/2025: </strong>Enrolled in Summer Research Internship Program in <strong><u>Academia Sinica</u></strong>!!!</p>
			<p><strong>ğŸ… 03/2025: </strong>Awarded with <strong>Academic Excellence Award (æ›¸å·ç)</strong>!!!</p>
			<p><strong>ğŸ… 03/2025: </strong>Awarded with <strong>Core Fundamental Course Award (æ ¸å¿ƒåŸºç¤èª²ç¨‹ç)</strong> of Algorithm !!!</p>
			<p><strong>ğŸ’¼ 02/2025: </strong>Enrolled as Brain Consultant in <strong><u>WorldQuant</u></strong>!!!</p>
			<p><strong>ğŸ… 11/2024: </strong>Awarded with <strong>Academic Excellence Award (æ›¸å·ç)</strong>!!!</p>
			<p><strong>ğŸ… 09/2024: </strong>Awarded with <strong>Core Fundamental Course Award (æ ¸å¿ƒåŸºç¤èª²ç¨‹ç)</strong> of Discrete Mathematics & Digital Circuit Design !!!</p>
			<p><strong>ğŸ… 03/2024: </strong>Awarded with <strong>Academic Excellence Award (æ›¸å·ç)</strong>!!!</p>
		</div>
	</div>

	<div class="container section-offset" id="Publications">
		<h2 class="section-title">Publications</h2>

		<div class="row publication">
			<div class="col-lg-4">
				<video class="video" style="max-width: 100%;" loop playsinline autoplay muted>
					<source src="files\4DGRT\coffee_martinirt_rolling_shutter.mp4" />
				</video>
			</div>
			<div class="col-lg-8">
				<p class=""><strong>Every Camera Effect, Every Time, All at Once: 4D Gaussian Ray Tracing for Physics-based Camera Effect Data Generation</strong></p>
				Yi-Ruei Liu*, <strong>You-Zhe Xie*</strong>, Yu-Hsiang Hsu*, <a href="https://ishengfang.github.io/">I-Sheng Fang</a>, <a href="https://yulunalexliu.github.io/">Yu-Lun Liu</a>, <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>
				<p>Authorship: <strong>co-1st</strong> author</p>
				<p><strong>NeurIPS 2025 <a href="https://space-in-vision-language-embodied-ai.github.io/">SpaVLE</a> Workshop</strong> (Poster) ğŸ”¥</p>
				<p class="intro">
					4DGRT identify problems about limited understanding of camera-effect video generation model, and proposes a data generation pipeline to synthesize videos with physically-accurate camera effect through apply ray tracing on dynamic 3DGS (4DGS).
					4DGRT also construct and release a paired dataset containing 8 dynamic indoor scenes with multi-view videos under four camera effects.
				</p>
					<a class="btn disabled" href="#">
						<i class="fab fas fa-globe-asia"></i>&nbsp project page
					</a>
					<a class="btn" href="https://www.arxiv.org/abs/2509.10759">
						<i class="ai ai-arxiv"></i>&nbsp arXiv
					</a>
					<a class="btn" href="https://github.com/shigon255/4DGRT">
						<i class="fab fa-github"></i>&nbsp Code
					</a>
					<a class="btn disabled" href="#">
						<i class="fab fa-youtube"></i>&nbsp Video
					</a>
			</div>
		</div>

		<div class="row publication">
			<div class="col-lg-4">
				<video class="video" style="max-width: 100%;" loop playsinline autoplay muted>
					<source src="files/StealthAttack/stealthAttack_trim.mp4" />
				</video>
			</div>
			<div class="col-lg-8">
				<p class=""><strong>StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions</strong></p>
				<a href="https://hentci.github.io/">Bo-Hsu Ke</a>, <strong>You-Zhe Xie</strong>, <a href="https://yulunalexliu.github.io/">Yu-Lun Liu</a>, <a href="https://walonchiu.github.io/">Wei-Chen Chiu</a>
				<p>Authorship: <strong>2nd</strong> author</p>
				<p><strong>ICCV 2025 (Poster) ğŸ”¥</strong></p>
				<p class="intro">
					StealthAttack proposes a novel density-guided poisoning method for 3D Gaussian Splatting (3DGS) that strategically injects illusory objects into low-density regions to create viewpoint-dependent visual illusions. 
					The method combines point cloud poisoning with adaptive noise scheduling to disrupt multi-view consistency, enabling successful attacks where illusions are clearly visible from target views while maintaining high fidelity in innocent viewpoints.
				</p>
					<a class="btn" href="https://hentci.github.io/stealthattack/">
						<i class="fab fas fa-globe-asia"></i>&nbsp project page
					</a>
					<a class="btn disabled" href="#">
						<i class="ai ai-arxiv"></i>&nbsp arXiv
					</a>
					<a class="btn" href="https://github.com/Hentci/StealthAttack_official">
						<i class="fab fa-github"></i>&nbsp Code
					</a>
					<a class="btn disabled" href="#">
						<i class="fab fa-youtube"></i>&nbsp Video
					</a>
			</div>
		</div>

	</div>
		

	
	
	</div>

	<div class="container section-offset" id="Projects">
		<h2 class="section-title">Projects</h2>

		<div class="row publication">
			<div class="col-lg-4">
				<img src='images/RT_DSTNet.png'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://youzhe0305.github.io/Team-Project/Real-Time-DSTNet/">Real-Time DSTNet</a></p>
				<strong>08/2024</strong>
				<p class="intro">
					Improved the <a href="https://github.com/xuboming8/DSTNet" target="_blank">DSTNet</a> model from the CVPR 2023 paper, which originally focused on offline video deblurring.
					Our enhancement transforms it into an online architecture that can perform real-time deblurring as new frames arrive.
					Additionally, we reduced the inference time to 0.027 seconds per frame (37 fps) and built a complete system to enable real-time deblurring.</p>	
				<!-- <p class="author"><strong>You-Zhe Xie</strong>, <a href="https://ztzhang.info/">Zhoutong Zhang</a>, <a href="http://kmatzen.com/">Kevin Blackburn-Matzen</a>, <a href="https://sniklaus.com/welcome">Simon Niklaus</a>, <a href="https://jimmie33.github.io/">Jianming Zhang</a>, <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>, <a href="https://pages.cs.wisc.edu/~fliu/">Feng Liu</a></p> -->
				<a class="btn" href="https://youzhe0305.github.io/Team-Project/Real-Time-DSTNet/">
					<i class="fas fa-info-circle"></i>&nbsp Intro Page</a>					
				<a class="btn" href="https://github.com/youzhe0305/Real-Time-DSTNet">
					<i class="fab fa-github"></i>&nbsp Code</a>
				<a class="btn" href="https://youzhe0305.github.io/Team-Project/Real-Time-DSTNet/Real_Time_DSTNet_Poster.png">
					<i class="fas fa-bullhorn"></i>&nbsp Poster</a>
				<!-- <a class="btn" href="https://youtu.be/e4LrUpUBsMA">
					<i class="fab fa-youtube"></i>&nbsp Video</a> -->
			</div>
		</div>
		<div class="row publication">
			<div class="col-lg-4">
				<img src='images/AnimeHelper.png'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://youzhe0305.github.io/Team-Project/Anime-Helper/">Anime Helper</a></p>
				<strong>12/2024</strong>
				<p class="intro"> 
					Anime Helper, an anime information integration website based on the MyAnimeList dataset. 
					Its features include anime search, categorization, sorting, login/logout, favorites list, comments, and ratings.</p>	
				<!-- <p class="author"><strong>You-Zhe Xie</strong>, <a href="https://ztzhang.info/">Zhoutong Zhang</a>, <a href="http://kmatzen.com/">Kevin Blackburn-Matzen</a>, <a href="https://sniklaus.com/welcome">Simon Niklaus</a>, <a href="https://jimmie33.github.io/">Jianming Zhang</a>, <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>, <a href="https://pages.cs.wisc.edu/~fliu/">Feng Liu</a></p> -->
				<a class="btn" href="https://youzhe0305.github.io/Team-Project/Anime-Helper/">
					<i class="fas fa-info-circle"></i>&nbsp Intro Page</a>					
				<a class="btn" href="https://github.com/youzhe0305/Real-Time-DSTNet">
					<i class="fab fa-github"></i>&nbsp Code</a>
				<a class="btn" href="https://youtu.be/evQajoC1g4c">
					<i class="fab fa-youtube"></i>&nbsp Video</a>
			</div>
		</div>
		<div class="row publication">
			<div class="col-lg-4">
				<img src='images/LLMPaperSearchingBot.png'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://youzhe0305.github.io/Team-Project/LLM-paper-search/">LLM supported paper searching bot</a></p>
				<strong>06/2024</strong>
				<p class="intro"> 
					Web scraping to collect the latest research papers with Selenium and analyze their content. The system utilizes RAG technology, implemented as a local database that allows the LLM to search for papers that meet the userâ€™s description and are sufficiently recent without network connection. Using a Discord Bot as UI</p>	
				<!-- <p class="author"><strong>You-Zhe Xie</strong>, <a href="https://ztzhang.info/">Zhoutong Zhang</a>, <a href="http://kmatzen.com/">Kevin Blackburn-Matzen</a>, <a href="https://sniklaus.com/welcome">Simon Niklaus</a>, <a href="https://jimmie33.github.io/">Jianming Zhang</a>, <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>, <a href="https://pages.cs.wisc.edu/~fliu/">Feng Liu</a></p> -->
				<a class="btn" href="https://youzhe0305.github.io/Team-Project/LLM-paper-search/">
					<i class="fas fa-info-circle"></i>&nbsp Intro Page</a>					
				<a class="btn" href="https://github.com/youzhe0305/Intro-AI-Final-Project">
					<i class="fab fa-github"></i>&nbsp Code</a>
				<a class="btn" href="https://youtu.be/8r9ehgZSaWo">
					<i class="fab fa-youtube"></i>&nbsp Video</a>
			</div>
		</div>
		<div class="row publication">
			<div class="col-lg-4">
				<img src='images/dungeon_game.png'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://youzhe0305.github.io/Personal-Project/text-based-dungeon-game/">C++ Text-Based Dungeon Game</a></p>
				<strong>04/2024</strong>
				<p class="intro"> 
					Text-Based Dungeon Game includes generated dungeons, turn-based combat, equipment system and a skill system, with 25 types of equipment and 10 types of skills designed. In the dungeon, players encounter various monsters, and defeating them allows players to acquire their skills. Along the way, players also meet different NPCs with whom they can trade or trigger special events to learn unique skills.</p>	
				<!-- <p class="author"><strong>You-Zhe Xie</strong>, <a href="https://ztzhang.info/">Zhoutong Zhang</a>, <a href="http://kmatzen.com/">Kevin Blackburn-Matzen</a>, <a href="https://sniklaus.com/welcome">Simon Niklaus</a>, <a href="https://jimmie33.github.io/">Jianming Zhang</a>, <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>, <a href="https://pages.cs.wisc.edu/~fliu/">Feng Liu</a></p> -->
				<a class="btn" href="https://youzhe0305.github.io/Personal-Project/text-based-dungeon-game/">
					<i class="fas fa-info-circle"></i>&nbsp Intro Page</a>					
				<a class="btn" href="https://github.com/youzhe0305/Text-Based-Dungeon-Game">
					<i class="fab fa-github"></i>&nbsp Code</a>
				<a class="btn" href="https://youtu.be/GfCF2AjKM00">
					<i class="fab fa-youtube"></i>&nbsp Video</a>
			</div>
		</div>
	</div>

		<!-- <div class="row publication">
			<div class="col-lg-4">
				<img src='images/shape-aware-video-editing.gif'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://text-video-edit.github.io/">Shape-aware Text-driven Layered Video Editing</a></p>
				<p class="author"><strong>Yao-Chih Lee</strong>, <a href="#">Ji-Ze Genevieve Jang</a>, <a  href="https://jamie725.github.io/website/">Yi-Ting Chen</a>, <a href="#">Elizabeth Qiu</a>, <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a></p>
				<p class="venue">CVPR 2023</p>
				<a class="btn" href="https://text-video-edit.github.io/">
					<i class="fab fas fa-globe-asia"></i>&nbsp Project page</a>
				<a class="btn" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Shape-Aware_Text-Driven_Layered_Video_Editing_CVPR_2023_paper.pdf">
					<i class="fas fa-file-pdf"></i>&nbsp Paper</a>
				<a class="btn" href="https://github.com/text-video-edit/shape-aware-text-driven-layered-video-editing-release">
					<i class="fab fa-github"></i>&nbsp Code</a>
			</div>
		</div> -->

		

		<!-- <div class="row publication">
			<div class="col-lg-4">
				<img src='images/deep3d-stabilizer.gif'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://yaochih.github.io/deep3d-stabilizer.io/">3D Video Stabilization with Depth Estimation by CNN-based Optimization</a></p>
				<p class="author"><strong>Yao-Chih Lee</strong>, <a href="https://kuan-wei-tseng.github.io/">Kuan-Wei Tseng</a>, Yu-Ta Chen, Chien-Cheng Chen, <a href="https://imp.iis.sinica.edu.tw/">Chu-Song Chen</a>, <a href="https://www.csie.ntu.edu.tw/~hung/index.html#about">Yi-Ping Hung</a></p>
				<p class="venue">CVPR 2021</p>
				<a class="btn" href="https://yaochih.github.io/deep3d-stabilizer.io/">
					<i class="fab fas fa-globe-asia"></i>&nbsp Project page</a>
				<a class="btn" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_3D_Video_Stabilization_With_Depth_Estimation_by_CNN-Based_Optimization_CVPR_2021_paper.pdf">
					<i class="fas fa-file-pdf"></i>&nbsp Paper</a>
				<a class="btn" href="https://github.com/yaochih/Deep3D-Stabilizer-release">
					<i class="fab fa-github"></i>&nbsp Code</a>
				<a class="btn" href="https://youtu.be/pMluFVA7NDQ">
					<i class="fab fa-youtube"></i>&nbsp Video</a>
				<a class="btn" href="https://github.com/yaochih/awesome-video-stabilization">
					<i class="fab fas fa-list-ul"></i>&nbsp Awesome video stabilization</a>
			</div>
		</div> -->
		
		<!-- <br/><hr/><br/>
		<h2 class="section-title">Others</h2>

		<div class="row publication">
			<div class="col-lg-4">
				<img src='images/latent-diffusion-prior.gif'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://latent-diffusion-prior.github.io/">Text-driven Visual Synthesis with Latent Diffusion Prior</a></p>
				<p class="author"><a href="https://tinghliao.github.io/">Ting-Hsuan Liao</a>, <a  href="http://songweige.github.io/">Songwei Ge</a>, <a href="https://twizwei.github.io/">Yiran Xu</a>, <strong>Yao-Chih Lee</strong>, <a href="https://badouralbahar.github.io/">Badour AlBahar</a>, <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a></p>
				<p class="venue">arXiv preprint 2023</p>
				<a class="btn" href="https://latent-diffusion-prior.github.io/">
					<i class="fab fas fa-globe-asia"></i>&nbsp Project page</a>
				<a class="btn" href="https://arxiv.org/abs/2301.13173">
					<i class="ai ai-arxiv"></i>&nbsp arXiv</a>
			</div>
		</div>

		<div class="row publication">
			<div class="col-lg-4">
				<img src='images/gcvd.gif'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://arxiv.org/abs/2208.02709">GCVD: Globally-Consistent Video Depth and Pose Estimation with Efficiency</a></p>
				<p class="author"><strong>Yao-Chih Lee</strong>, <a href="https://kuan-wei-tseng.github.io/">Kuan-Wei Tseng</a>, Guan-Sheng Chen, <a href="https://imp.iis.sinica.edu.tw/">Chu-Song Chen</a></p>
				<p class="venue">arXiv preprint 2022</p>
				<a class="btn" href="https://arxiv.org/abs/2208.02709">
					<i class="ai ai-arxiv"></i>&nbsp arXiv</a>
				<a class="btn" href="https://github.com/yaochih/GCVD-release">
					<i class="fab fa-github"></i>&nbsp Code</a>
			</div>
		</div>

		<div class="row publication">
			<div class="col-lg-4">
				<img src='images/pixstabnet.png'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://ieeexplore.ieee.org/document/9506801">PixStabNet: Fast Deep Online Video Stabilization</a></p>
				<p class="author">Yu-Ta Chen, <a href="https://kuan-wei-tseng.github.io/">Kuan-Wei Tseng</a>, <strong>Yao-Chih Lee</strong>, Chun-Yu Chen, and <a href="https://www.csie.ntu.edu.tw/~hung/index.html#about">Yi-Ping Hung</a></p>
				<p class="venue">ICIP 2021</p>
				<a class="btn" href="https://ieeexplore.ieee.org/document/9506801">
					<i class="fas fa-file-pdf"></i>&nbsp Paper</a>
			</div>
		</div>

		<div class="row publication">
			<div class="col-lg-4">
				<img src='images/part-aware-human-pose-cvprw-2021.png'>
			</div>
			<div class="col-lg-8">
				<p class="title"><a href="https://arxiv.org/abs/2106.11589">Part-aware Measurement for Robust Multi-View Multi-Human 3D Pose Estimation and Tracking</a></p>
				<p class="author">Hau Chu, Jia-Hong Lee, <strong>Yao-Chih Lee</strong>, Ching-Hsien Hsu, Jia-Da Li, and <a href="https://imp.iis.sinica.edu.tw/">Chu-Song Chen</a></p>
				<p class="venue">CVPR Workshop 2021</p>
				<a class="btn" href="https://arxiv.org/abs/2106.11589">
					<i class="fas fa-file-pdf"></i>&nbsp Paper</a>
			</div>
		</div>
	</div> -->
	<!-- End of publications -->

	<!-- <br><br><br><br> -->

	<footer class="container">
		<span style="font-size: 16px;">The webpage template is borrowed from <a href="https://chenwei891213.github.io/">Chen-Wei Chang</a>, which was originally designed by <a href="https://dribbble.com/shots/4342703-Minimal-resume-freebie-for-junior-self-taught-people">Nicolas Meuzard</a>.</span>
		<div class="container text-center" style="width: 400px; height: 300px;">
			<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=z8fwpRWmn8PZNEp2jPF4fNLZWWw120kVcSfOslruvuU&cl=ffffff&w=a"></script>
		</div>
	</footer>

	<script src="js/jquery.min.js"></script> <!-- jQuery for Bootstrap's JavaScript plugins -->
	<script src="js/bootstrap.min.js"></script> <!-- Bootstrap framework -->
	<script src="js/jquery.easing.min.js"></script> <!-- jQuery Easing for smooth scrolling between anchors -->
    <script src="js/swiper.min.js"></script> <!-- Swiper for image and text sliders -->
    <script src="js/jquery.magnific-popup.js"></script> <!-- Magnific Popup for lightboxes -->
	<script src="https://unpkg.com/scrollreveal@4.0.0/dist/scrollreveal.min.js"></script>
	<script src="js/animation.js"></script>

</body>
</html>
